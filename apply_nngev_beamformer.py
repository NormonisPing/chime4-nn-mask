#!/usr/bin/env python
# coding=utf-8
# wujian@17.11.9

import os
import tqdm
import json
import argparse
import chime_data

import torch as th
import numpy as np
from torch.autograd import Variable

from model import MaskComputer, MaskEstimator 
from fgnt.beamforming import gev_wrapper_on_masks
from fgnt.signal_processing import audiowrite, stft, istft


num_bins = 513

def get_flist_simu_from_json(chime_data_dir, stage, json_name):
    json_path = os.path.join(chime_data_dir, 'annotations', json_name)
    with open(json_path, 'r') as f:
        annotations = json.load(f)
    # each item is a string
    flist = [os.path.join(chime_data_dir, 'audio', '16kHz', 'isolated', \
            '{}_{}_simu'.format(stage, a['environment'].lower()), \
            '{}_{}_{}'.format(a['speaker'], a['wsj_name'], \
            a['environment'])) for a in annotations]
    return flist
    

def get_flist_real_from_json(chime_data_dir, json_name):
    json_path = os.path.join(chime_data_dir, 'annotations', json_name)
    with open(json_path, 'r') as f:
        annotations = json.load(f)
    # each item is a tuple
    flist_tuples = [(os.path.join(chime_data_dir, 'audio', '16kHz', \
                    'embedded', a['wavfile']), a['start'], a['end'], \
                    a['wsj_name']) for a in annotations]
    return flist_tuples

# {dt|et}05_{bus|caf|ped|str}_{real|simu}
def apply_beamfomer(args):
    estimator = MaskEstimator(num_bins) 
    mask_computer = MaskComputer(estimator, args.model)
    name_split = args.json.split('_')
    stage, atype = name_split[0], name_split[1]
    assert atype in ['simu', 'real'] and stage in ['dt05', 'et05']
    flist = get_flist_simu_from_json(args.chime_dir, stage, args.json) \
            if atype == 'simu' else get_flist_real_from_json(args.chime_dir, args.json)
    print('load {} utterance from {}'.format(len(flist), args.json))
    for f in flist:
        context = 0
        if atype == 'simu':
            samples = chime_data.get_audio_data(f)
            basename = os.path.basename(f).split('_')
            spk, wsj_name, env = basename[0], basename[1], basename[-1]
        if atype == 'real':
            # wavename, start_time, end_time
            samples, context = chime_data.get_audio_data_with_context(f[0], f[1], f[2])
            basename = os.path.basename(f[0]).split('_')
            wsj_name = f[3]
            spk, env = basename[0], basename[-1]
        input_specs = stft(samples, time_dim=1).transpose((1, 0, 2))
        mask_n, mask_x = mask_computer.compute_masks(np.abs(input_specs).astype(np.float32))
        mask_n = np.median(mask_n, axis=1)
        mask_x = np.median(mask_x, axis=1)
        clean_specs = gev_wrapper_on_masks(input_specs, mask_n, mask_x) 
        clean_samples = istft(clean_specs)[int(context): ]
        output_dir = os.path.join(args.enhan_dir, "{}_{}_{}".format(stage, env.lower(), atype))
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        filename = os.path.join(output_dir, "{}_{}_{}.wav".format(spk, wsj_name, env.upper()))
        print('write {} done'.format(filename))
        audiowrite(clean_samples, filename, 16000, True, True)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Command to apply GEV beamformer, using masks\
                                                  estimated by specified model(default using GPU)")
    parser.add_argument("model", type=str, 
                        help="path of model states generated by train_estimator.py")
    parser.add_argument("json", type=str, 
                        help="path of {dt|et}05_{simu|real}_{jobid}.json file")
    parser.add_argument("--enhan-dir", type=str, default="nngev_6mics", dest="enhan_dir",
                        help="output directory of enhanced data")
    parser.add_argument("--chime-dir", type=str, default="../CHiME4/data", dest="chime_dir",
                        help="directory of official chime data")
    args = parser.parse_args()
    apply_beamfomer(args)
